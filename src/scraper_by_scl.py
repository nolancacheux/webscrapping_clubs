"""
Scraper optimis√© utilisant directement les num√©ros d'affiliation (scl)
pour acc√©der aux pages de d√©tail des clubs.
"""

import json
import time
from typing import List, Optional
from playwright.sync_api import sync_playwright, Page, Browser
from dataclasses import dataclass
import re


@dataclass
class ClubData:
    """Structure de donn√©es pour un club"""
    nom: str
    numero_affiliation: Optional[str] = None
    email: Optional[str] = None  # Coalesce: email_principal ou email_officiel
    telephone: Optional[str] = None
    adresse: Optional[str] = None
    url_detail: Optional[str] = None
    
    # Champs internes pour extraction (non utilis√©s dans la sortie finale)
    email_officiel: Optional[str] = None
    email_principal: Optional[str] = None


class SCLScraper:
    """Scraper utilisant les num√©ros d'affiliation (scl)"""
    
    def __init__(self, headless: bool = True, slow_mo: int = 0):
        """
        Initialise le scraper.
        
        Args:
            headless: Mode headless du navigateur
            slow_mo: D√©lai entre les actions (ms)
        """
        self.headless = headless
        self.slow_mo = slow_mo
        self.browser: Optional[Browser] = None
        self.page: Optional[Page] = None
    
    def __enter__(self):
        """Context manager entry"""
        self.playwright = sync_playwright().start()
        launch_options = {
            'slow_mo': self.slow_mo
        }
        if self.headless:
            launch_options['headless'] = True
        
        try:
            self.browser = self.playwright.chromium.launch(**launch_options)
        except Exception as e:
            if 'headless_shell' in str(e) or 'Executable doesn\'t exist' in str(e):
                print("‚ö†Ô∏è  Probl√®me avec chromium_headless_shell, utilisation de chromium normal...")
                launch_options.pop('headless', None)
                self.browser = self.playwright.chromium.launch(**launch_options)
            else:
                raise
        
        self.page = self.browser.new_page()
        self.page.set_extra_http_headers({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager exit"""
        if self.browser:
            self.browser.close()
        if hasattr(self, 'playwright'):
            self.playwright.stop()
    
    def extract_club_by_scl(self, scl: int, base_url: str = "https://gironde.fff.fr") -> Optional[ClubData]:
        """
        Extrait les donn√©es d'un club par son num√©ro d'affiliation.
        
        Args:
            scl: Num√©ro d'affiliation du club
            base_url: URL de base du district (peu importe, le scl est unique)
            
        Returns:
            Objet ClubData avec les informations extraites, ou None si le club n'existe pas
        """
        url = f"{base_url}/recherche-clubs?scl={scl}"
        
        try:
            # Utiliser "domcontentloaded" au lieu de "networkidle" pour √©viter les attentes infinies
            # Certaines pages peuvent avoir des requ√™tes r√©seau qui ne se terminent jamais
            try:
                self.page.goto(url, wait_until="domcontentloaded", timeout=5000)  # Timeout de 5s pour fiabilit√©
            except Exception as e:
                # Si timeout, essayer une fois de plus
                try:
                    self.page.goto(url, wait_until="domcontentloaded", timeout=5000)  # Timeout de 5s pour fiabilit√©
                except:
                    return None
            # Attendre un peu pour que le contenu Angular se charge
            time.sleep(0.3)  # D√©lai de 0.3s pour laisser Angular charger le contenu
            
            # V√©rifier si la page contient un club valide
            # Si le club n'existe pas, la page peut √™tre vide ou contenir un message d'erreur
            page_text = self.page.content()
            
            # Chercher le num√©ro d'affiliation dans la page
            affil_match = re.search(r'N[¬∞\s]*affiliation[:\s]*(\d+)', page_text, re.IGNORECASE)
            if not affil_match:
                # Pas de club trouv√© √† ce num√©ro
                return None
            
            numero_affiliation = affil_match.group(1)
            
            # Extraire le nom du club d'abord pour v√©rifier si c'est un vrai club
            nom = None
            try:
                # Strat√©gie 1: Chercher dans le h1 avec la structure Angular (app-club)
                # Structure: <h1>CLUB DISTRICT GERS</h1><h2>N¬∞affiliation: 6504</h2>
                try:
                    # Chercher le h1 dans le composant Angular app-club
                    h1_elements = self.page.query_selector_all('app-club h1, .club-title h1, h1')
                    for h1 in h1_elements:
                        text = h1.inner_text().strip()
                        text_lower = text.lower()
                        
                        # Filtrer les √©l√©ments de navigation
                        excluded = ['accueil', 'gironde', 'paris', 'ensemble', '√©crivons']
                        is_excluded = any(word in text_lower for word in excluded)
                        
                        # Exclure "district de la" mais pas "club district" ou "club ligue"
                        if 'district de la' in text_lower or ('district de' in text_lower and 'club district' not in text_lower):
                            is_excluded = True
                        
                        # Ne pas exclure si c'est "CLUB LIGUE" (ex: "CLUB LIGUE ALSACE")
                        if 'club ligue' in text_lower:
                            is_excluded = False
                        
                        if (text and len(text) > 5 and len(text) < 100 and
                            not is_excluded and
                            any(c.isalpha() for c in text)):
                            nom = text
                            break
                except Exception as e:
                    # Ignorer les erreurs dans cette strat√©gie
                    pass
                
                # Strat√©gie 2: Chercher le nom dans le contenu HTML avec regex
                if not nom:
                    excluded_words = ['accueil', 'gironde', 'paris', 
                                     'ensemble', '√©crivons', 'r√©sultats', 'calendrier']
                    # Ne pas exclure "ligue" si c'est dans "CLUB LIGUE"
                    
                    nom_patterns = [
                        # Pattern 1: Nom dans h1 avant h2 avec "N¬∞affiliation"
                        r'<h1[^>]*>([A-Z][A-Z\s\.\-\']{5,80}?)</h1>\s*<h2[^>]*>N[¬∞\s]*affiliation',
                        # Pattern 2: Nom avant "N¬∞affiliation" dans h2
                        r'<h2[^>]*>([A-Z][A-Z\s\.\-\']{5,80}?)</h2>\s*N[¬∞\s]*affiliation[:\s]*\d+',
                        # Pattern 3: Nom en majuscules avant "N¬∞affiliation" (texte brut)
                        r'([A-Z][A-Z\s\.\-\']{5,80}?)\s*N[¬∞\s]*affiliation[:\s]*\d+',
                    ]
                    
                    for pattern in nom_patterns:
                        match = re.search(pattern, page_text, re.IGNORECASE | re.DOTALL)
                        if match:
                            potential_nom = match.group(1).strip()
                            potential_nom_lower = potential_nom.lower()
                            
                            # Filtrer les faux positifs
                            # Exclure seulement si c'est "District de la X" ou "Ligue de X", pas "CLUB DISTRICT X"
                            is_excluded = False
                            for word in excluded_words:
                                if word in potential_nom_lower:
                                    # V√©rifier le contexte - si c'est "district de la" ou "ligue de", exclure
                                    if word == 'district' and ('district de la' in potential_nom_lower or 
                                                               'district de' in potential_nom_lower and 
                                                               'club district' not in potential_nom_lower):
                                        is_excluded = True
                                        break
                                    elif word != 'district':  # Pour les autres mots, exclure directement
                                        is_excluded = True
                                        break
                            
                            if (len(potential_nom) > 5 and len(potential_nom) < 100 and
                                not is_excluded and
                                any(c.isalpha() for c in potential_nom) and
                                (len(potential_nom.split()) > 1 or len(potential_nom) > 8)):
                                nom = potential_nom
                                break
                
                # Strat√©gie 2: Chercher dans les √©l√©ments HTML pr√®s du num√©ro d'affiliation
                if not nom:
                    # Trouver l'√©l√©ment qui contient le num√©ro d'affiliation
                    try:
                        affil_element = self.page.query_selector('text=/N[¬∞\\s]*affiliation/i')
                        if affil_element:
                            # Chercher le h2 le plus proche AVANT le num√©ro d'affiliation
                            all_h2 = self.page.query_selector_all('h2')
                            
                            # Obtenir la position du num√©ro d'affiliation
                            affil_box = affil_element.bounding_box()
                            if affil_box:
                                affil_y = affil_box['y']
                                
                                # Trouver le h2 le plus proche au-dessus
                                closest_h2 = None
                                min_distance = float('inf')
                                
                                for h2 in all_h2:
                                    h2_box = h2.bounding_box()
                                    if h2_box:
                                        h2_y = h2_box['y']
                                        # H2 doit √™tre au-dessus (y plus petit) et proche
                                        if h2_y < affil_y and (affil_y - h2_y) < 300:
                                            distance = affil_y - h2_y
                                            if distance < min_distance:
                                                min_distance = distance
                                                closest_h2 = h2
                                
                                if closest_h2:
                                    text = closest_h2.inner_text().strip()
                                    text_lower = text.lower()
                                    
                                    # Filtrer les √©l√©ments de navigation
                                    # Ne pas exclure "district" si c'est dans "CLUB DISTRICT X"
                                    excluded_words = ['accueil', 'ligue', 'gironde', 'paris', 
                                                     'ensemble', '√©crivons', 'r√©sultats', 'calendrier',
                                                     '√©quipes', 'staff', 'terrains', 'si√®ge social']
                                    is_excluded = False
                                    for word in excluded_words:
                                        if word in text_lower:
                                            is_excluded = True
                                            break
                                    # Exclure "district de la" mais pas "club district"
                                    if 'district de la' in text_lower or 'district de' in text_lower:
                                        if 'club district' not in text_lower:
                                            is_excluded = True
                                    
                                    if (text and len(text) > 5 and len(text) < 100 and
                                        not is_excluded and
                                        any(c.isalpha() for c in text) and
                                        (len(text.split()) > 1 or len(text) > 8)):
                                        nom = text
                    except:
                        pass
                    
                    # Si toujours pas trouv√©, chercher tous les h2 et filtrer
                    if not nom:
                        excluded_words = ['accueil', 'ligue', 'gironde', 'paris', 
                                         'ensemble', '√©crivons', 'n¬∞affiliation', 'r√©sultats',
                                         'calendrier', '√©quipes', 'staff', 'terrains', 'si√®ge social',
                                         'installations', 'rencontres', 'prochaines', 'derni√®res']
                        
                        h2_elements = self.page.query_selector_all('h2')
                        for h2 in h2_elements:
                            text = h2.inner_text().strip()
                            text_lower = text.lower()
                            
                            is_navigation = False
                            for word in excluded_words:
                                if word in text_lower:
                                    is_navigation = True
                                    break
                            # Exclure "district de la" mais pas "club district"
                            if 'district de la' in text_lower or ('district de' in text_lower and 'club district' not in text_lower):
                                is_navigation = True
                            
                            if (text and len(text) > 5 and len(text) < 100 and
                                not is_navigation and
                                any(c.isalpha() for c in text) and
                                (len(text.split()) > 1 or len(text) > 8)):
                                nom = text
                                break
                    
                    # Si pas trouv√©, chercher dans les autres √©l√©ments
                    if not nom:
                        excluded_words = ['accueil', 'ligue', 'gironde', 'paris', 
                                         'ensemble', '√©crivons', 'r√©sultats', 'calendrier',
                                         '√©quipes', 'staff', 'terrains', 'si√®ge social']
                        
                        nom_selectors = [
                            'h1:not([class*="title"]):not([class*="slogan"])',
                            '[class*="club-name"]',
                            '[class*="name-club"]',
                            'strong',
                        ]
                        for selector in nom_selectors:
                            try:
                                elements = self.page.query_selector_all(selector)
                                for element in elements:
                                    text = element.inner_text().strip()
                                    text_lower = text.lower()
                                    
                                    is_excluded = False
                                    for word in excluded_words:
                                        if word in text_lower:
                                            is_excluded = True
                                            break
                                    # Exclure "district de la" mais pas "club district"
                                    if 'district de la' in text_lower or ('district de' in text_lower and 'club district' not in text_lower):
                                        is_excluded = True
                                    
                                    if (text and len(text) > 5 and len(text) < 100 and
                                        not is_excluded and
                                        any(c.isalpha() for c in text) and
                                        (len(text.split()) > 1 or len(text) > 8)):
                                        nom = text
                                        break
                                if nom:
                                    break
                            except:
                                continue
                
                # Strat√©gie 3: Chercher dans le titre de la page
                if not nom:
                    title = self.page.title()
                    if title:
                        # Extraire le nom du titre (g√©n√©ralement avant le premier | ou -)
                        title_parts = re.split(r'[|\-]', title)
                        if title_parts:
                            potential_nom = title_parts[0].strip()
                            if (len(potential_nom) > 5 and 
                                'recherche' not in potential_nom.lower() and
                                'district' not in potential_nom.lower()):
                                nom = potential_nom
            except Exception as e:
                print(f"      ‚ö†Ô∏è  Erreur extraction nom: {e}")
                pass
            
            if not nom:
                return None
            
            # Accepter le num√©ro d'affiliation "0" si un nom de club valide a √©t√© trouv√©
            # (ex: "CLUB FEDERATION FRANCAISE DE FOOTBALL" a affiliation 0)
            # Le num√©ro "0" est valide pour certains clubs sp√©ciaux comme la FFF elle-m√™me
            if numero_affiliation == "0" and nom:
                # C'est valide, continuer avec l'extraction
                pass
            elif not numero_affiliation:
                return None
            
            # Extraire les emails (am√©lior√© pour trouver tous les types)
            email_principal = None
            email_officiel = None
            email_autre = None
            
            # Chercher "Email principal" d'abord (priorit√© 1)
            email_patterns_principal = [
                r'Email principal[:\s]*([a-zA-Z0-9._-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})',
                r'<b>Email principal</b>\s*:\s*([a-zA-Z0-9._-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})',
                r'Email principal[:\s]*([^\s<>]+@[^\s<>]+)',
            ]
            
            for pattern in email_patterns_principal:
                match = re.search(pattern, page_text, re.IGNORECASE | re.DOTALL)
                if match:
                    email_principal = match.group(1).strip()
                    break
            
            # Chercher "Email officiel" (priorit√© 2)
            email_patterns_officiel = [
                r'Email officiel[:\s]*([a-zA-Z0-9._-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})',
                r'<b>Email officiel</b>\s*:\s*([a-zA-Z0-9._-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})',
            ]
            
            for pattern in email_patterns_officiel:
                match = re.search(pattern, page_text, re.IGNORECASE | re.DOTALL)
                if match:
                    email_officiel = match.group(1).strip()
                    break
            
            # Chercher "Email autre" (priorit√© 3)
            email_patterns_autre = [
                r'Email autre[:\s]*([a-zA-Z0-9._-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})',
                r'<b>Email autre</b>\s*:\s*([a-zA-Z0-9._-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})',
                r'Email autre[:\s]*([^\s<>]+@[^\s<>]+)',
            ]
            
            for pattern in email_patterns_autre:
                match = re.search(pattern, page_text, re.IGNORECASE | re.DOTALL)
                if match:
                    # Peut contenir plusieurs emails s√©par√©s par des virgules
                    emails_str = match.group(1).strip()
                    # Prendre le premier email si plusieurs
                    email_autre = emails_str.split(',')[0].strip()
                    break
            
            # Coalesce: email_principal > email_officiel > email_autre
            email = email_principal or email_officiel or email_autre
            
            # Extraire le t√©l√©phone (am√©lior√© pour trouver tous les types)
            telephone_travail = None
            telephone_domicile = None
            telephone_autre = None
            mobile_personnel = None
            
            # Chercher "T√©l√©phone travail" (priorit√© 1)
            # Patterns am√©lior√©s pour capturer les num√©ros avec espaces et formats courts
            phone_patterns_travail = [
                r'T√©l√©phone travail\s*:\s*([0-9\s\.\-\(\)]{6,})',
                r'<b>T√©l√©phone travail</b>\s*:\s*([0-9\s\.\-\(\)]{6,})',
                r'T√©l√©phone travail[:\s]+([0-9\s\.\-\(\)]{6,})',
            ]
            
            for pattern in phone_patterns_travail:
                match = re.search(pattern, page_text, re.IGNORECASE | re.DOTALL)
                if match:
                    phone_raw = match.group(1).strip()
                    # Nettoyer et extraire uniquement les chiffres
                    phone_clean = re.sub(r'[^\d]', '', phone_raw)
                    # Accepter les num√©ros de 6 chiffres minimum (certains num√©ros courts existent)
                    if len(phone_clean) >= 6:
                        telephone_travail = phone_clean
                        break
            
            # Chercher "T√©l√©phone domicile" (priorit√© 2)
            phone_patterns_domicile = [
                r'T√©l√©phone domicile\s*:\s*([0-9\s\.\-\(\)]{6,})',
                r'<b>T√©l√©phone domicile</b>\s*:\s*([0-9\s\.\-\(\)]{6,})',
                r'T√©l√©phone domicile[:\s]+([0-9\s\.\-\(\)]{6,})',
            ]
            
            for pattern in phone_patterns_domicile:
                match = re.search(pattern, page_text, re.IGNORECASE | re.DOTALL)
                if match:
                    phone_raw = match.group(1).strip()
                    phone_clean = re.sub(r'[^\d]', '', phone_raw)
                    if len(phone_clean) >= 6:
                        telephone_domicile = phone_clean
                        break
            
            # Chercher "Mobile personnel" (priorit√© 3)
            phone_patterns_mobile = [
                r'Mobile personnel\s*:\s*([0-9\s\.\-\(\)]{6,})',
                r'<b>Mobile personnel</b>\s*:\s*([0-9\s\.\-\(\)]{6,})',
                r'Mobile personnel[:\s]+([0-9\s\.\-\(\)]{6,})',
            ]
            
            for pattern in phone_patterns_mobile:
                match = re.search(pattern, page_text, re.IGNORECASE | re.DOTALL)
                if match:
                    phone_raw = match.group(1).strip()
                    phone_clean = re.sub(r'[^\d]', '', phone_raw)
                    if len(phone_clean) >= 6:
                        mobile_personnel = phone_clean
                        break
            
            # Chercher "T√©l√©phone autre" (priorit√© 4) - peut y en avoir plusieurs
            phone_patterns_autre = [
                r'T√©l√©phone autre\s*:\s*([0-9\s\.\-\(\)]{6,})',
                r'<b>T√©l√©phone autre</b>\s*:\s*([0-9\s\.\-\(\)]{6,})',
                r'T√©l√©phone autre[:\s]+([0-9\s\.\-\(\)]{6,})',
            ]
            
            for pattern in phone_patterns_autre:
                # Chercher toutes les occurrences (peut y en avoir plusieurs)
                matches = re.finditer(pattern, page_text, re.IGNORECASE | re.DOTALL)
                for match in matches:
                    phone_raw = match.group(1).strip()
                    phone_clean = re.sub(r'[^\d]', '', phone_raw)
                    if len(phone_clean) >= 6:
                        # Prendre le premier trouv√©
                        if not telephone_autre:
                            telephone_autre = phone_clean
                        break
                if telephone_autre:
                    break
            
            # Chercher "T√©l√©phone" g√©n√©rique (priorit√© 5)
            if not telephone_travail and not telephone_domicile and not mobile_personnel and not telephone_autre:
                phone_patterns_generic = [
                    r'T√©l√©phone\s*:\s*([0-9\s\.\-\(\)]{6,})',
                    r'Tel\s*:\s*([0-9\s\.\-\(\)]{6,})',
                ]
                
                for pattern in phone_patterns_generic:
                    match = re.search(pattern, page_text, re.IGNORECASE | re.DOTALL)
                    if match:
                        phone_raw = match.group(1).strip()
                        phone_clean = re.sub(r'[^\d]', '', phone_raw)
                        if len(phone_clean) >= 6:
                            telephone_autre = phone_clean
                            break
            
            # Coalesce: travail > domicile > mobile > autre
            telephone = telephone_travail or telephone_domicile or mobile_personnel or telephone_autre
            
            # Extraire l'adresse (Si√®ge social)
            adresse = None
            # Chercher dans la structure Angular sp√©cifique
            try:
                # Structure: <span class="title-ground">Si√®ge social</span><br><b>Adresse :</b><span> Route de lavacant   - 32000 - AUCH </span>
                # Chercher directement le span avec l'adresse apr√®s "Adresse :"
                address_span = self.page.query_selector('.txt-map-siege b:contains("Adresse") + span', timeout=1000)
                if address_span:
                    adresse = address_span.inner_text().strip()
                else:
                    # Fallback: chercher dans tous les spans
                    address_elements = self.page.query_selector_all('.txt-map-siege span', timeout=1000)
                    for elem in address_elements[:10]:  # Limiter √† 10 pour √©viter les boucles longues
                        try:
                            text = elem.inner_text().strip()
                            if 'adresse' in text.lower() and len(text) > 15:
                                # Extraire l'adresse apr√®s "Adresse :"
                                match = re.search(r'Adresse\s*:\s*(.+)', text, re.IGNORECASE)
                                if match:
                                    adresse = match.group(1).strip()
                                    break
                        except:
                            continue
            except:
                pass
            
            # Fallback: regex dans le HTML
            if not adresse:
                # Pattern pour trouver l'adresse apr√®s "Adresse :"
                address_patterns = [
                    r'<b>Adresse\s*:</b>\s*<span[^>]*>([^<]+)</span>',
                    r'Adresse\s*:\s*([^<\n]+(?:-\s*\d{5}\s*-\s*[A-Z\s]+)?)',
                    r'Si√®ge social[:\s]*([^<]+)',
                ]
                
                for pattern in address_patterns:
                    address_match = re.search(pattern, page_text, re.IGNORECASE | re.DOTALL)
                    if address_match:
                        adresse = re.sub(r'<[^>]+>', '', address_match.group(1)).strip()
                        # Nettoyer l'adresse
                        adresse = re.sub(r'\s+', ' ', adresse)
                        if len(adresse) > 10:  # V√©rifier que c'est une adresse valide
                            break
            
            club_data = ClubData(
                nom=nom,
                numero_affiliation=numero_affiliation,
                email=email,  # Coalesce: email_principal ou email_officiel
                telephone=telephone,
                adresse=adresse,
                url_detail=url,
                email_officiel=email_officiel,  # Gard√© pour r√©f√©rence interne
                email_principal=email_principal  # Gard√© pour r√©f√©rence interne
            )
            
            return club_data
            
        except Exception as e:
            # Ne pas afficher les erreurs de timeout, c'est normal pour les num√©ros invalides
            if "timeout" not in str(e).lower() and "timeout" not in str(type(e)).lower():
                print(f"      ‚ö†Ô∏è  Erreur pour scl={scl}: {e}")
            return None
    
    def scrape_range(self, start_scl: int, end_scl: int, base_url: str = "https://gironde.fff.fr", 
                     progress_interval: int = 100) -> List[ClubData]:
        """
        Scrape une plage de num√©ros d'affiliation.
        
        Args:
            start_scl: Num√©ro de d√©but
            end_scl: Num√©ro de fin
            base_url: URL de base du district
            progress_interval: Afficher le progr√®s tous les N clubs
            
        Returns:
            Liste des clubs trouv√©s
        """
        clubs_data = []
        total = end_scl - start_scl + 1
        
        print(f"üî¢ Scraping des num√©ros scl de {start_scl} √† {end_scl} ({total} clubs √† tester)\n")
        
        for scl in range(start_scl, end_scl + 1):
            if (scl - start_scl) % progress_interval == 0:
                progress = ((scl - start_scl) / total) * 100
                print(f"  üìä Progression: {progress:.1f}% ({scl - start_scl}/{total}) - {len(clubs_data)} clubs trouv√©s")
            
            club_data = self.extract_club_by_scl(scl, base_url)
            
            if club_data:
                clubs_data.append(club_data)
                if len(clubs_data) <= 5 or (scl - start_scl) % progress_interval == 0:
                    print(f"    ‚úÖ scl={scl}: {club_data.nom}")
        
        print(f"\n‚úÖ Scraping termin√©: {len(clubs_data)} clubs trouv√©s sur {total} test√©s")
        return clubs_data


def main():
    """Fonction principale pour tester le scraper par scl"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Scrape les clubs FFF par num√©ro d'affiliation")
    parser.add_argument('--start', type=int, default=1, help='Num√©ro scl de d√©but')
    parser.add_argument('--end', type=int, default=100, help='Num√©ro scl de fin')
    parser.add_argument('--base-url', type=str, default='https://gironde.fff.fr', 
                       help='URL de base (peu importe, le scl est unique)')
    parser.add_argument('--headless', action='store_true', help='Mode headless')
    parser.add_argument('--output', type=str, default='clubs_scl_scraped.json', 
                       help='Fichier de sortie JSON')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("üèÜ SCRAPING PAR NUM√âRO D'AFFILIATION (SCL)")
    print("=" * 60)
    print(f"Plage: {args.start} - {args.end}")
    print(f"URL de base: {args.base_url}")
    print("=" * 60)
    print()
    
    with SCLScraper(headless=args.headless if args.headless else True, slow_mo=0) as scraper:
        clubs_data = scraper.scrape_range(args.start, args.end, args.base_url)
        
        # Sauvegarder les r√©sultats
        if clubs_data:
            with open(args.output, 'w', encoding='utf-8') as f:
                json.dump([club.__dict__ for club in clubs_data], f, indent=2, ensure_ascii=False)
            
            print(f"\nüíæ R√©sultats sauvegard√©s dans: {args.output}")
            print(f"\nüìä Statistiques:")
            print(f"   Clubs trouv√©s: {len(clubs_data)}")
            print(f"   Taux de r√©ussite: {(len(clubs_data)/(args.end-args.start+1)*100):.2f}%")
            
            # Afficher quelques exemples
            print(f"\nüìã Exemples de clubs trouv√©s:")
            for club in clubs_data[:5]:
                print(f"   - {club.nom} (scl: {club.numero_affiliation})")
                if club.email_officiel:
                    print(f"     üìß {club.email_officiel}")
                if club.telephone:
                    print(f"     üìû {club.telephone}")
        else:
            print("\n‚ö†Ô∏è  Aucun club trouv√© dans cette plage")


if __name__ == "__main__":
    main()

